---
title: 网站数据爬取
category: python
order: 1
---



```python
import requests
from lxml import etree
from apscheduler.schedulers.blocking import BlockingScheduler

def getContent(url, xpathDetail):
  page = requests.get(url)
  html = etree.HTML(page.content)
  html = html.xpath(xpathDetail)
  if len(html) > 0:
    html = etree.tostring(html[0], encoding = "utf-8", pretty_print = True, method = "html").decode("utf-8")
  return html

# 数据爬取
def zgtq(url, xpath, xpathDetail):
  page = requests.get(url)
  html = etree.HTML(page.content)
  html_data = html.xpath(xpath)
  print(html_data)
  for a in html_data:
    title = a.text
    url = a.get('href')
    content = getContent(url, xpathDetail)
    if content and url and title :
      # TODO 存入Mysql
      print(title)
      print(url)
      print(content)
  print(url + '爬取成功')

# 定时任务,每隔5s执行
# 爬取网站
url = 'http://news.weather.com.cn'
# 目标超链接XPATH
xpath = '//div[@class="newcard"][position()=1]/p/a'
# 详情内容XPATH
xpathDetail = '//div[@class="articleBody"][position()=1]'
scheduler = BlockingScheduler()
scheduler.add_job(zgtq, 'interval', seconds=5, args = [url, xpath, xpathDetail])
scheduler.start()
```

